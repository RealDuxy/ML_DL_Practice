{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取前1000条新闻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外自本周6月12日起除小米手机6等15款机型外其余机型已暂停更新发布含开发版体验版内测稳定版暂不受影响以确保工程师可以集中全部精力进行系统优化工作有人猜测这也是将精力主要用到MIUI9的研发之中MIUI8去年5月发布距今已有一年有余也是时候更新换代了当然关于MIUI9的确切信息我们还是等待官方消息\\n',\n",
       " '骁龙835作为唯一通过Windows10桌面平台认证的ARM处理器高通强调不会因为只考虑性能而去屏蔽掉小核心相反他们正联手微软找到一种适合桌面平台的兼顾性能和功耗的完美方案报道称微软已经拿到了一些新的源码以便Windows10更好地理解biglittle架构资料显示骁龙835作为一款集成了CPUGPU基带蓝牙WiFi的SoC比传统的Wintel方案可以节省至少30的PCB空间按计划今年Q4华硕惠普联想将首发骁龙835Win10电脑预计均是二合一形态的产品当然高通骁龙只是个开始未来也许还能见到三星Exynos联发科华为麒麟小米澎湃等进入Windows10桌面平台\\n']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = \"/Users/duxy/Downloads/Study/NLP/NLP技能班/dateset/article_9k.txt\"\n",
    "with open(data_path) as f:\n",
    "    data = f.readlines()\n",
    "data = data[:1000]\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 统计词频，词频较高的单字作为停用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['此外', '自', '本周', '6', '月']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "join_data = \" \".join(data)\n",
    "seg_data = jieba.lcut(join_data)\n",
    "seg_data[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_count = Counter(seg_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['的',\n",
       " '在',\n",
       " '了',\n",
       " '是',\n",
       " '和',\n",
       " '也',\n",
       " '有',\n",
       " '月',\n",
       " '将',\n",
       " '他',\n",
       " '年',\n",
       " '对',\n",
       " '等',\n",
       " '都',\n",
       " '为',\n",
       " '日',\n",
       " '中',\n",
       " '不',\n",
       " '上',\n",
       " '与',\n",
       " '就',\n",
       " '我',\n",
       " '被',\n",
       " '6',\n",
       " '到',\n",
       " '人',\n",
       " '这',\n",
       " '但',\n",
       " '\\n',\n",
       " ' ',\n",
       " '后',\n",
       " '从',\n",
       " '还',\n",
       " '说',\n",
       " '并',\n",
       " '会',\n",
       " '而',\n",
       " '让',\n",
       " '要']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STOP_WORDS = [word for word, count in word_count.most_common(50) if len(word)==1 ]\n",
    "STOP_WORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "创立一个图结构，每个词为一个点，初始权重为1， 每个边代表着同在一个滑动窗口内。\n",
    "设立停止更新的阈值\n",
    "设立滑动窗口\n",
    "设立每一步更新的公式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextRank():\n",
    "    def __init__(self, data, d = 0.85, sliding_window=5):\n",
    "        self.nodes, self.edges = self.build_graph(data,sliding_window)\n",
    "        self.d = d\n",
    "    \n",
    "    def build_graph(self, data, sliding_window): # 若slidingwindow为偶数，则自动加1\n",
    "        if sliding_window % 2 == 0:\n",
    "            sliding_window += 1\n",
    "        \n",
    "        mid = int((sliding_window-1)/2)\n",
    "        nodes = defaultdict(int) # word: 1\n",
    "        edges = defaultdict(set) # w_i: {w_1,w_2....w_n}\n",
    "        # 读取前500条数据\n",
    "        for i, line in enumerate(data):\n",
    "            if i % 100 == 0:\n",
    "                print(i)\n",
    "            # 分词\n",
    "            word_list = jieba.lcut(line)\n",
    "            # 分词后去除停用词，并pad两边\n",
    "            word_list = [\"<PAD>\"]* mid +[ w for w in word_list if w not in STOP_WORDS] + [\"<PAD>\"]* mid\n",
    "            for index,word in enumerate(word_list):\n",
    "                if word != \"<PAD>\":\n",
    "                    nodes[word] = 1\n",
    "                    for w in word_list[index-mid:index]+word_list[index+1:index+mid]:\n",
    "                        if w != \"<PAD>\":\n",
    "                            edges[word].add(w)\n",
    "        return nodes, edges\n",
    "        \n",
    "    def update_graph(self, threshold = 0.0001):\n",
    "        converge = False\n",
    "        step = 1\n",
    "        nodes = defaultdict(int) \n",
    "        edges = defaultdict(set) \n",
    "        while not converge:\n",
    "            for item in self.nodes.items():\n",
    "                word, value = item[0],item[1]\n",
    "                \n",
    "                # 对每个词更新\n",
    "                temp = 0\n",
    "                for w in self.edges[word]:\n",
    "                    w1 = 1\n",
    "                    w2 = len(self.edges[w])\n",
    "                    w3 = self.nodes[w]\n",
    "                    temp += w1*w3/w2\n",
    "        \n",
    "                nodes[word] = (1-self.d) + self.d * temp\n",
    "            \n",
    "            print(f\"step {step}\")\n",
    "            print(f\"before: {sum(self.nodes.values())}  after: {sum(nodes.values())}\")\n",
    "            \n",
    "            # 每个词的误差小于threshold，则说明拟合\n",
    "            converge = True\n",
    "            for word, value in self.nodes.items(): \n",
    "                if abs(value - nodes[word]) > threshold:\n",
    "                    converge = False\n",
    "                    break\n",
    "            step+=1\n",
    "            self.nodes = nodes.copy()\n",
    "            \n",
    "\n",
    "            \n",
    "        \n",
    "    def most_important(self,n=10):\n",
    "        sorted_node = sorted(self.nodes.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_node[:n]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('此外', 1),\n",
       " ('自', 1),\n",
       " ('本周', 1),\n",
       " ('12', 1),\n",
       " ('日起', 1),\n",
       " ('除', 1),\n",
       " ('小米', 1),\n",
       " ('手机', 1),\n",
       " ('15', 1),\n",
       " ('款', 1)]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_graph = TextRank(data)\n",
    "text_graph.most_important()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 1\n",
      "before: 47179  after: 47275.90128843367\n",
      "step 2\n",
      "before: 47275.90128843367  after: 47269.16801039471\n",
      "step 3\n",
      "before: 47269.16801039471  after: 47276.1090060111\n",
      "step 4\n",
      "before: 47276.1090060111  after: 47277.494686260354\n",
      "step 5\n",
      "before: 47277.494686260354  after: 47278.85987788125\n",
      "step 6\n",
      "before: 47278.85987788125  after: 47279.56629484144\n",
      "step 7\n",
      "before: 47279.56629484144  after: 47280.08758346987\n",
      "step 8\n",
      "before: 47280.08758346987  after: 47280.447744710305\n",
      "step 9\n",
      "before: 47280.447744710305  after: 47280.725101135555\n",
      "step 10\n",
      "before: 47280.725101135555  after: 47280.94114781092\n",
      "step 11\n",
      "before: 47280.94114781092  after: 47281.116252525724\n",
      "step 12\n",
      "before: 47281.116252525724  after: 47281.25987246578\n",
      "step 13\n",
      "before: 47281.25987246578  after: 47281.37957378442\n",
      "step 14\n",
      "before: 47281.37957378442  after: 47281.47990719601\n",
      "step 15\n",
      "before: 47281.47990719601  after: 47281.564574155855\n",
      "step 16\n",
      "before: 47281.564574155855  after: 47281.636171299666\n",
      "step 17\n",
      "before: 47281.636171299666  after: 47281.69688143705\n",
      "step 18\n",
      "before: 47281.69688143705  after: 47281.748389306296\n",
      "step 19\n",
      "before: 47281.748389306296  after: 47281.79213249488\n",
      "step 20\n",
      "before: 47281.79213249488  after: 47281.829281141094\n",
      "step 21\n",
      "before: 47281.829281141094  after: 47281.86083707851\n",
      "step 22\n",
      "before: 47281.86083707851  after: 47281.88763711875\n",
      "step 23\n",
      "before: 47281.88763711875  after: 47281.9103971611\n",
      "step 24\n",
      "before: 47281.9103971611  after: 47281.92972190446\n",
      "step 25\n",
      "before: 47281.92972190446  after: 47281.94612777448\n",
      "step 26\n",
      "before: 47281.94612777448  after: 47281.96005286426\n",
      "step 27\n",
      "before: 47281.96005286426  after: 47281.97187065871\n",
      "step 28\n",
      "before: 47281.97187065871  after: 47281.98189841804\n",
      "step 29\n",
      "before: 47281.98189841804  after: 47281.99040623156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('中国', 95.85619687211546),\n",
       " ('一个', 86.99951396907784),\n",
       " ('我们', 73.45948587492227),\n",
       " ('没有', 69.89860317859183),\n",
       " ('表示', 68.6541238262555),\n",
       " ('以', 67.07719752021484),\n",
       " ('进行', 65.4721626362417),\n",
       " ('自己', 65.2132334853605),\n",
       " ('他们', 64.04627841066265),\n",
       " ('已经', 63.3684225956056)]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_graph.update_graph()\n",
    "text_graph.most_important()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.0",
   "language": "python",
   "name": "tf2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
